<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Session 40: Lab 15 - Advanced Case Studies & Ethical Dilemmas - Module V</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <!-- Chosen Palette: "Warm Neutral Harmony" -->
    <!-- Application Structure Plan: Definitive single session lab guide. Structure: Header, Export, Details, Objectives, Lab Intro, Interactive Case Study Selector with extensive business/ethical cases, a new interactive Bias Mitigation simulation, a new Stakeholder Analysis task, a structured analysis framework, and footer. Goal: A definitive guide for analyzing the complex technical and ethical dimensions of Big Data applications with extensive tasks and visuals. -->
    <!-- Visualization & Content Choices: 
        - Extensive, detailed case studies covering complex scenarios.
        - An interactive tab system to switch between case studies.
        - An interactive "Ethical Dilemma" simulator for each case study.
        - A new interactive bar chart visualization to simulate algorithmic bias mitigation.
        - All content presented in standard HTML.
        - PDF Export: Print-specific CSS.
    -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body { 
            font-family: 'Inter', sans-serif; 
            font-size: 1rem; 
            line-height: 1.625; 
        }
        
        h1.page-title { font-size: 2.25rem; line-height: 2.5rem; } 
        h2.section-title { font-size: 1.5rem; line-height: 2rem; margin-bottom: 0.75rem;} 
        h3.subsection-title { font-size: 1.25rem; line-height: 1.75rem; margin-bottom: 0.5rem;}    
        h4.detail-title { font-size: 1.125rem; line-height: 1.75rem; margin-bottom: 0.375rem;} 
        
        .case-study-tab {
            transition: all 0.2s ease-in-out;
        }
        .case-study-tab.active {
            transform: translateY(-2px);
            background-color: #1d4ed8; /* blue-700 */
            color: white;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
        }
        .case-study-content {
            display: none;
        }
        .case-study-content.active {
            display: block;
        }
        
        .dilemma-choice {
            cursor: pointer;
            transition: all 0.2s;
        }
        .dilemma-choice:hover {
            border-color: #3b82f6;
            transform: translateY(-2px);
        }
        .dilemma-feedback {
            margin-top: 1rem;
            padding: 1rem;
            border-radius: 0.375rem;
            font-size: 0.875rem;
        }
        .feedback-pro { background-color: #f0fdf4; border-left: 4px solid #22c55e; }
        .feedback-con { background-color: #fff1f2; border-left: 4px solid #f43f5e; }

        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 300px;
            max-height: 350px;
            margin-top: 1.5rem;
            margin-bottom: 1.5rem;
        }

        @media print {
            body { font-size: 10pt; line-height: 1.3; } 
            .no-print { display: none !important; }
            header { display: flex; flex-direction: column; align-items: center; text-align: center; }
            .header-logo-print { max-width: 150px; max-height: 50px; margin-bottom: 10px; } 
            .footer-logo-print { max-width: 100px; max-height: 30px; margin-top: 10px; } 
            footer { text-align: center; }
            section, .content-section { page-break-inside: avoid; margin-bottom: 15px; } 
            .bg-white { box-shadow: none !important; border: 1px solid #ccc; padding: 0.5rem !important;}
            a { text-decoration: none; color: black; }
            .case-study-selector { display: none; }
            .case-study-content { display: block !important; border-top: 1px solid #ccc; padding-top: 1rem; margin-top: 1rem; }
            .chart-container { display: none; }
            h1.page-title { font-size: 20pt; } 
            h2.section-title { font-size: 16pt; }
            h3.subsection-title { font-size: 14pt; }
            h4.detail-title { font-size: 12pt; }
        }
    </style>
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
</head>
<body class="bg-gray-100 text-gray-800"> 
    <div class="container mx-auto p-4 md:p-8"> 
        <header class="mb-10"> 
            <div class="flex flex-col sm:flex-row items-center justify-between">
                <img src="../faceprep-logo-multicolor.png" alt="FACE Prep Logo" class="h-16 md:h-20 mb-4 sm:mb-0 header-logo-print" onerror="this.style.display='none'; this.onerror=null;"> 
                <div class="text-center sm:text-right sm:ml-4"> 
                    <p class="text-base text-gray-500">Module V: Advanced Topics, Ethics, and Project Conclusion</p> 
                    <h1 class="page-title text-3xl md:text-4xl font-bold text-gray-900 mt-1">Session 40: Lab 15 - Advanced Case Studies & Ethical Dilemmas</h1> 
                    <p class="text-lg text-gray-600 mt-2">Data Mining & Big Data Analytics</p> 
                </div>
            </div>
            <nav aria-label="Breadcrumb" class="mt-4 text-sm text-gray-500 no-print"> 
                <ol class="list-none p-0 inline-flex">
                    <li class="flex items-center">
                        <a href="../index.html" class="text-slate-600 hover:text-slate-800">Course Overview</a>
                        <span class="mx-2">/</span> 
                    </li>
                    <li class="flex items-center">
                        <a href="module-5-index.html" class="text-slate-600 hover:text-slate-800">Module V</a>
                        <span class="mx-2">/</span> 
                    </li>
                    <li class="text-gray-700 font-semibold" aria-current="page">Session 40</li> 
                </ol>
            </nav>
        </header>

        <article class="bg-white p-6 md:p-8 rounded-lg shadow-lg"> 
            
            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 1: Case Study Selection</h2>
                <p class="text-base text-gray-700 leading-relaxed mb-4">
                    Select a case study from the tabs below. Read it carefully, interact with all demos, and then prepare to answer the analysis questions in the subsequent tasks.
                </p>
                <div class="case-study-selector no-print">
                    <div class="flex flex-wrap border-b border-gray-300">
                        <button class="case-study-tab py-2 px-4 text-sm font-medium text-gray-600 hover:bg-gray-200 rounded-t-md" data-case="policing">Predictive Policing</button>
                        <button class="case-study-tab py-2 px-4 text-sm font-medium text-gray-600 hover:bg-gray-200 rounded-t-md" data-case="insurance">Dynamic Insurance Pricing</button>
                    </div>
                </div>
                
                <div id="case-study-container" class="mt-4">
                    <!-- Case Study content will be injected here by JS -->
                </div>
            </section>

            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 2: In-depth Technical & Architectural Analysis</h2>
                <p class="text-base text-gray-700 leading-relaxed mb-4">
                    For your selected case study, move beyond the business problem and analyze the underlying technology.
                </p>
                <ul class="list-decimal list-inside text-base text-gray-700 ml-5 space-y-2">
                    <li><strong>Propose a Technology Stack:</strong> Which specific cloud services and Spark components would be needed? (e.g., Kafka for ingestion, Spark Streaming for processing, Spark MLlib for modeling, HDFS/S3 for storage).</li>
                    <li><strong>Justify the Choices:</strong> Explain *why* a streaming solution like Spark Streaming is necessary over a batch solution like standard Spark or MapReduce for your chosen case.</li>
                    <li><strong>Estimate Data Scale:</strong> What would you estimate the data volume and velocity to be? (e.g., "Terabytes per day," "thousands of events per second"). How does this scale justify the use of Big Data tools?</li>
                </ul>
            </section>
            
            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 3: Stakeholder Impact Analysis</h2>
                <p class="text-base text-gray-700 leading-relaxed mb-4">
                   Identify all potential stakeholders for your chosen case study and analyze how the proposed solution would positively or negatively affect each one.
                </p>
                 <ul class="list-disc list-inside text-base text-gray-700 ml-5 space-y-2">
                    <li><strong>Primary Stakeholders:</strong> e.g., the company, the direct customers/users.</li>
                    <li><strong>Secondary Stakeholders:</strong> e.g., company employees, competitors, regulators.</li>
                     <li><strong>External Stakeholders:</strong> e.g., the general public, specific communities, government bodies.</li>
                </ul>
            </section>

            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 4: Structured Ethical Framework Application</h2>
                <p class="text-base text-gray-700 leading-relaxed mb-4">
                    Apply the F.A.T.E. framework to your chosen case study.
                </p>
                <ul class="list-decimal list-inside text-base text-gray-700 ml-5 space-y-4">
                    <li><strong>Fairness:</strong> Could the model produce unfair or discriminatory outcomes? How?</li>
                    <li><strong>Accountability:</strong> Who is responsible if the model makes a harmful prediction?</li>
                    <li><strong>Transparency:</strong> Is the model's decision-making process explainable?</li>
                    <li><strong>Ethics:</strong> Is using this model for this purpose "right"? What are the societal consequences?</li>
                </ul>
            </section>
        </article>

        <footer class="text-center mt-12 py-6 border-t border-gray-300"> 
            <div class="mb-4"> 
                 <img src="../faceprep-logo-multicolor.png" alt="FACE Prep Logo" class="h-10 mx-auto footer-logo-print" onerror="this.style.display='none'; this.onerror=null;"> 
            </div>
            <p class="text-base text-gray-600">&copy; <span id="currentYearModule"></span> FACE Prep Campus (www.faceprep.in). All rights reserved.</p>
        </footer>
    </div>

    <script>
        document.getElementById('currentYearModule').textContent = new Date().getFullYear();
        
        const caseStudyContainer = document.getElementById('case-study-container');
        const caseStudyTabs = document.querySelectorAll('.case-study-tab');
        let currentChart = null;

        const caseStudies = {
            policing: {
                title: "Case Study 1: Predictive Policing Model",
                content: `
                    <div class="prose max-w-none text-gray-700">
                        <p><strong>Background:</strong> A city's police department wants to use data to be more proactive about crime prevention. They have years of historical crime data, including location. The goal is to build a model that predicts which city blocks are most likely to experience crime, so patrols can be directed to high-risk areas.</p>
                        
                        <div id="bias-sim-container" class="bg-gray-100 p-4 rounded-lg my-6 no-print">
                            <h4 class="detail-title font-semibold text-gray-700 text-center">Interactive Demo: Bias Mitigation</h4>
                            <p class="text-sm text-gray-600 mb-4 text-center">The model is trained on historical arrest data, which is biased due to historical over-policing in District A. See how this affects the model's predictions.</p>
                             <div class="flex justify-center items-center flex-wrap gap-2 mb-4">
                                <button class="bg-red-500 hover:bg-red-600 text-white font-semibold py-2 px-4 rounded-lg shadow" id="bias-raw-btn">Train on Raw, Biased Data</button>
                                <button class="bg-green-500 hover:bg-green-600 text-white font-semibold py-2 px-4 rounded-lg shadow" id="bias-fixed-btn">Train on Re-balanced Data</button>
                            </div>
                            <div class="chart-container" style="height:250px;"><canvas id="biasChart"></canvas></div>
                        </div>

                        <h4 class="detail-title font-semibold text-gray-700 mt-4">Ethical Dilemma</h4>
                        <p class="text-sm text-gray-600 mb-3">You discover the model's bias. This will create a feedback loop: more police sent to District A will lead to more arrests, "proving" the model right. What do you recommend?</p>
                        <div class="grid grid-cols-1 md:grid-cols-2 gap-4" id="dilemma-policing">
                            <div class="dilemma-choice p-4 border-2 rounded-lg" data-choice="deploy"><strong>Deploy the Model:</strong> Argue it's better than random patrols and can be improved later.</div>
                            <div class="dilemma-choice p-4 border-2 rounded-lg" data-choice="reject"><strong>Reject the Model:</strong> Argue that deploying a known biased model is unethical and will erode community trust.</div>
                        </div>
                        <div id="feedback-policing" class="dilemma-feedback" style="display:none;"></div>
                    </div>`
            },
            insurance: {
                title: "Case Study 2: Dynamic Insurance Pricing",
                content: `
                     <div class="prose max-w-none text-gray-700">
                        <p><strong>Background:</strong> An auto insurance company wants to move to personalized premiums using telematics data from a smartphone app (speeding, hard braking, time of day, etc.).</p>
                        <p><strong>Proposed Solution:</strong> A regression model will calculate a daily risk score for each driver to adjust their monthly premium.</p>
                        <h4 class="detail-title font-semibold text-gray-700 mt-4">Ethical Dilemma</h4>
                        <p class="text-sm text-gray-600 mb-3">The model reveals that drivers from lower-income zip codes, who often work night shifts, receive higher risk scores because driving at night is statistically riskier. The model is indirectly penalizing them for their socio-economic status.</p>
                        <p class="font-semibold mb-2">The marketing team wants to launch. What is your recommendation?</p>
                         <div class="grid grid-cols-1 md:grid-cols-2 gap-4" id="dilemma-insurance">
                            <div class="dilemma-choice p-4 border-2 rounded-lg" data-choice="launch"><strong>Launch as Planned:</strong> Argue the model is accurately pricing risk based on observed behavior.</div>
                            <div class="dilemma-choice p-4 border-2 rounded-lg" data-choice="adjust"><strong>Adjust the Model:</strong> Argue the model creates a discriminatory outcome and should be adjusted to remove or reduce the weight of correlated features like "time of day", even if it reduces overall accuracy.</div>
                        </div>
                        <div id="feedback-insurance" class="dilemma-feedback" style="display:none;"></div>
                    </div>`
            }
        };

        const dilemmaFeedback = {
            policing: {
                deploy: '<div class="feedback-pro"><strong>Potential Positive Outcome:</strong> Overall crime rates might decrease in the short term due to increased police presence in targeted areas.</div><div class="feedback-con mt-2"><strong>Potential Negative Outcome:</strong> Over-policing in targeted areas erodes community trust, leads to biased arrest statistics, and can perpetuate a cycle of systemic inequality.</div>',
                reject: '<div class="feedback-pro"><strong>Potential Positive Outcome:</strong> You uphold ethical standards and prevent the immediate deployment of a harmful, biased system, protecting vulnerable communities.</div><div class="feedback-con mt-2"><strong>Potential Negative Outcome:</strong> The police department misses an opportunity to optimize patrols, and the project may lose funding and momentum, delaying any potential data-driven improvements.</div>'
            },
            insurance: {
                launch: '<div class="feedback-pro"><strong>Potential Positive Outcome:</strong> The company launches a highly accurate and profitable pricing model. High-risk behaviors are correctly priced, and very safe drivers may see lower premiums.</div><div class="feedback-con mt-2"><strong>Potential Negative Outcome:</strong> The model is perceived as unfair and discriminatory, leading to public backlash, loss of customers in certain demographics, and potential regulatory scrutiny for "proxy discrimination".</div>',
                adjust: '<div class="feedback-pro"><strong>Potential Positive Outcome:</strong> The company launches a fairer model that avoids penalizing people for socio-economic factors, improving brand reputation and equity.</div><div class="feedback-con mt-2"><strong>Potential Negative Outcome:</strong> The adjusted model is less accurate at predicting risk, potentially leading to lower profitability. The company may be at a competitive disadvantage against rivals who use all available data.</div>'
            }
        };

        const setupDilemmaListeners = (caseKey) => {
            const dilemmaContainer = document.getElementById(`dilemma-${caseKey}`);
            if(dilemmaContainer) {
                dilemmaContainer.addEventListener('click', (e) => {
                    const choiceEl = e.target.closest('.dilemma-choice');
                    if (choiceEl) {
                         document.querySelectorAll(`#dilemma-${caseKey} .dilemma-choice`).forEach(el => el.classList.remove('bg-blue-100', 'border-blue-400'));
                         choiceEl.classList.add('bg-blue-100', 'border-blue-400');
                        const choice = choiceEl.dataset.choice;
                        const feedbackDiv = document.getElementById(`feedback-${caseKey}`);
                        feedbackDiv.innerHTML = dilemmaFeedback[caseKey][choice];
                        feedbackDiv.style.display = 'block';
                    }
                });
            }
        };
        
        const setupBiasSim = () => {
             const biasCtx = document.getElementById('biasChart');
             if(!biasCtx) return;
             
             const rawBtn = document.getElementById('bias-raw-btn');
             const fixedBtn = document.getElementById('bias-fixed-btn');

             const chartData = {
                labels: ['District A (Low-Income)', 'District B (High-Income)'],
                datasets: [
                    { label: 'Historical Arrests', data: [800, 200], backgroundColor: 'rgba(107, 114, 128, 0.7)' },
                    { label: 'Predicted High-Risk Patrols', data: [0, 0], backgroundColor: 'rgba(239, 68, 68, 0.7)' }
                ]
             };
             const biasChart = new Chart(biasCtx, {
                type: 'bar',
                data: chartData,
                options: { responsive: true, maintainAspectRatio: false, plugins: { title: {display: true, text: 'Model Prediction Based on Training Data'}, legend: {position: 'bottom'} }, scales: { y: { beginAtZero: true, title: {display: true, text: 'Number of Units'} } } }
             });

             rawBtn.addEventListener('click', () => {
                biasChart.data.datasets[1].data = [85, 15]; // Model reflects the bias
                biasChart.data.datasets[1].label = "Predicted Patrols (Biased)";
                biasChart.update();
             });
              fixedBtn.addEventListener('click', () => {
                biasChart.data.datasets[1].data = [55, 45]; // Model is fairer
                biasChart.data.datasets[1].label = "Predicted Patrols (Balanced)";
                biasChart.update();
             });
        };

        if (caseStudyContainer && caseStudyTabs.length > 0) {
            const showCaseStudy = (caseKey) => {
                caseStudyTabs.forEach(tab => {
                    if (tab.dataset.case === caseKey) tab.classList.add('active');
                    else tab.classList.remove('active');
                });
                caseStudyContainer.innerHTML = caseStudies[caseKey].content;
                setupDilemmaListeners(caseKey);
                if (caseKey === 'policing') {
                    setupBiasSim();
                }
            };
            caseStudyTabs.forEach(tab => {
                tab.addEventListener('click', () => showCaseStudy(tab.dataset.case));
            });
            caseStudyTabs[0].click();
        }

    </script>
</body>
</html>

