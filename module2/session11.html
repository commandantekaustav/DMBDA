<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Session 11: Lab 3 - Comprehensive Data Preprocessing with Python - Module II</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <!-- Chosen Palette: "Warm Neutral Harmony" -->
    <!-- Application Structure Plan: The definitive comprehensive lab guide. Structure: Header, Export, Session Details, Objectives, Setup, Detailed sections for Basic and Advanced Imputation methods (with full pros/cons/use-cases), integrated interactive demos for KNN (n_neighbors) and IterativeImputer (max_iter), a summary section on distributional effects with KDE visualization, followed by sections on Transformation and Encoding. Goal: A deep, practical, and fully interactive reference for all discussed data preprocessing techniques. -->
    <!-- Visualization & Content Choices: 
        - Well-commented Python code blocks.
        - Detailed textual explanations for every technique.
        - Interactive scatter plot (Chart.js) to visualize the effect of the n_neighbors hyperparameter in KNN Imputation.
        - Interactive line chart (Chart.js) to visualize the effect of the max_iter hyperparameter in IterativeImputer.
        - Kernel Density Estimate (KDE) plots using Chart.js to visually demonstrate imputation impact.
        - Interactive tooltips for technical terms.
        - PDF Export: Print-specific CSS.
    -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body { 
            font-family: 'Inter', sans-serif; 
            font-size: 1rem; 
            line-height: 1.625; 
        }
        
        .interactive-term { 
            cursor: pointer;
            font-weight: 600; 
        }
        .definition-tooltip {
            display: none;
            position: absolute;
            background-color: #f9fafb; 
            border: 1px solid #d1d5db; 
            padding: 8px; 
            border-radius: 4px; 
            box-shadow: 0 2px 4px rgba(0,0,0,0.1); 
            z-index: 100;
            font-size: 0.875rem; 
            width: max-content;
            max-width: 320px; 
        }

        h1.page-title { font-size: 2.25rem; line-height: 2.5rem; } 
        h2.section-title { font-size: 1.5rem; line-height: 2rem; margin-bottom: 0.75rem;} 
        h3.subsection-title { font-size: 1.25rem; line-height: 1.75rem; margin-bottom: 0.5rem;}    
        h4.detail-title { font-size: 1.125rem; line-height: 1.75rem; margin-bottom: 0.375rem;} 
        
        .code-block {
            background-color: #1e293b; /* slate-800 */
            color: #e2e8f0; /* slate-200 */
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.875rem;
            line-height: 1.5;
        }
        .code-block .comment { color: #94a3b8; /* slate-400 */ }
        .code-block .keyword { color: #7dd3fc; /* sky-400 */ }
        .code-block .string { color: #a5b4fc; /* indigo-300 */ }
        
        .technique-card {
            background-color: #f9fafb; /* gray-50 */
            border: 1px solid #e5e7eb; /* gray-200 */
            border-left-width: 4px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            border-radius: 0.5rem;
        }
        .basic-card { border-left-color: #f59e0b; /* amber-500 */ }
        .advanced-card { border-left-color: #10b981; /* emerald-500 */ }
        .viz-card { border-left-color: #6366f1; /* indigo-500 */}

        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 350px;
            max-height: 400px;
        }
        
        .selector-btn {
            transition: all 0.2s ease-in-out;
        }
        .selector-btn.active {
            transform: scale(1.1);
            background-color: #1d4ed8; /* blue-700 */
            color: white;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
        }

        @media print {
            body { font-size: 10pt; line-height: 1.3; } 
            .no-print { display: none !important; }
            header { display: flex; flex-direction: column; align-items: center; text-align: center; }
            .header-logo-print { max-width: 150px; max-height: 50px; margin-bottom: 10px; } 
            .footer-logo-print { max-width: 100px; max-height: 30px; margin-top: 10px; } 
            footer { text-align: center; }
            section, .content-section, .technique-card { page-break-inside: avoid; margin-bottom: 15px; } 
            .bg-white { box-shadow: none !important; border: 1px solid #ccc; padding: 0.5rem !important;}
            a { text-decoration: none; color: black; }
            .interactive-term { text-decoration: none; color: black; font-weight: bold; } 
            .definition-tooltip { display: none !important; }
            .code-block { background-color: #f3f4f6; color: #1f2937; border: 1px solid #ddd; white-space: pre-wrap; word-wrap: break-word; }
            .chart-container { display: none; }
            h1.page-title { font-size: 20pt; } 
            h2.section-title { font-size: 16pt; }
            h3.subsection-title { font-size: 14pt; }
            h4.detail-title { font-size: 12pt; }
        }
    </style>
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
</head>
<body class="bg-gray-100 text-gray-800"> 
    <div class="container mx-auto p-4 md:p-8"> 
        <header class="mb-10"> 
            <div class="flex flex-col sm:flex-row items-center justify-between">
                <img src="../faceprep-logo-multicolor.png" alt="FACE Prep Logo" class="h-16 md:h-20 mb-4 sm:mb-0 header-logo-print" onerror="this.style.display='none'; this.onerror=null;"> 
                <div class="text-center sm:text-right sm:ml-4"> 
                    <p class="text-base text-gray-500">Module II: Data Preprocessing & Core Mining Techniques</p> 
                    <h1 class="page-title text-3xl md:text-4xl font-bold text-gray-900 mt-1">Session 11: Lab 3 - Comprehensive Data Preprocessing with Python</h1> 
                    <p class="text-lg text-gray-600 mt-2">Data Mining & Big Data Analytics</p> 
                </div>
            </div>
            <nav aria-label="Breadcrumb" class="mt-4 text-sm text-gray-500 no-print"> 
                <ol class="list-none p-0 inline-flex">
                    <li class="flex items-center">
                        <a href="../index.html" class="text-slate-600 hover:text-slate-800">Course Overview</a>
                        <span class="mx-2">/</span> 
                    </li>
                    <li class="flex items-center">
                        <a href="module-2-index.html" class="text-slate-600 hover:text-slate-800">Module II</a>
                        <span class="mx-2">/</span> 
                    </li>
                    <li class="text-gray-700 font-semibold" aria-current="page">Session 11</li> 
                </ol>
            </nav>
        </header>

        <div class="text-center mb-8 no-print"> 
            <button onclick="window.print()" class="bg-slate-600 hover:bg-slate-700 text-white font-bold py-2 px-6 rounded-lg shadow-md transition duration-150 ease-in-out text-base"> 
                Export Session 11 to PDF
            </button>
        </div>

        <article class="bg-white p-6 md:p-8 rounded-lg shadow-lg"> 
            <section class="mb-6 border-b pb-4"> 
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-2">Session Details</h2> 
                <p class="text-base text-gray-700"><span class="font-semibold">Type:</span> Guided Practical ðŸ’»</p>
                <p class="text-base text-gray-700"><span class="font-semibold">Duration:</span> 2 Hours</p>
                <p class="text-base text-gray-700"><span class="font-semibold">Core Libraries:</span> Pandas, Numpy, Scikit-learn</p>
            </section>

            <section class="mb-8 content-section"> 
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Lab Objectives</h2> 
                <ul class="list-disc list-inside text-base text-gray-700 ml-5 space-y-1"> 
                    <li>Implement and contrast both basic and advanced strategies for handling missing data.</li>
                    <li>Analyze the impact of key hyperparameters (`n_neighbors` for KNN, `max_iter` for Iterative Imputer) through interactive visualizations.</li>
                    <li>Critically analyze and articulate how different imputation methods can affect the underlying distribution of a feature.</li>
                    <li>Apply a complete data preprocessing pipeline, including imputation, scaling, and encoding.</li>
                </ul>
            </section>

            <div class="definition-tooltip"></div>
            
            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 1: Loading and Inspecting a Sample Dataset</h2>
                 <div class="code-block">
                    <pre><code><span class="keyword">import</span> pandas <span class="keyword">as</span> pd
<span class="keyword">import</span> numpy <span class="keyword">as</span> np

data = {
    <span class="string">'Age'</span>: [25, 32, np.nan, 45, 22, 38, 50, 29, 41, np.nan, 60, 33],
    <span class="string">'Experience'</span>: [5, 10, 7, 20, 2, 15, 25, 6, 18, 12, 35, np.nan],
    <span class="string">'Salary'</span>: [70000, 90000, 65000, 120000, 45000, 95000, np.nan, 72000, 110000, 88000, 150000, 85000]
}
df = pd.DataFrame(data)
<span class="keyword">print</span>(df.isnull().sum())</code></pre>
                </div>
            </section>

            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 2: Basic Imputation Strategies</h2>
                <div class="technique-card basic-card">
                    <h3 class="subsection-title text-lg font-medium text-amber-700 mb-2">A. Dropping Missing Values</h3>
                    <p class="text-base text-gray-700 leading-relaxed"><strong>How it works:</strong> Any row (or column) containing one or more missing values is removed entirely from the dataset.</p>
                    <p class="text-sm font-semibold text-gray-600 mt-2">Pros:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>Very simple and fast.</li><li>Preserves the original distribution of the remaining data.</li></ul>
                    <p class="text-sm font-semibold text-gray-600 mt-2">Cons:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>Can lead to significant data loss if many rows have missing values.</li><li>May introduce bias if the missingness is not random.</li></ul>
                    <p class="text-sm font-semibold text-gray-600 mt-2">When to use:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>When the amount of missing data is very small (e.g., &lt;1-2% of the dataset).</li></ul>
                </div>
                <div class="technique-card basic-card">
                    <h3 class="subsection-title text-lg font-medium text-amber-700 mb-2">B. Mean / Median / Mode Imputation</h3>
                    <p class="text-base text-gray-700 leading-relaxed"><strong>How it works:</strong> Missing values in a column are replaced with a single statistic calculated from the non-missing values in that same column.</p>
                    <p class="text-sm font-semibold text-gray-600 mt-2">Pros:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>Simple, fast, and easy to implement.</li><li>Keeps the full dataset (no row deletion).</li></ul>
                    <p class="text-sm font-semibold text-gray-600 mt-2">Cons:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>Does not account for relationships between features.</li><li><strong>Significantly reduces the variance of the imputed feature.</strong></li><li><strong>Distorts the original data distribution by creating an artificial spike at the imputed value.</strong></li></ul>
                    <p class="text-sm font-semibold text-gray-600 mt-2">When to use:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>As a quick baseline model.</li><li>When the number of missing values is small and the distortion is acceptable.</li></ul>
                </div>
            </section>

            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 3: Advanced Imputation Strategies (Real-World Methods)</h2>
                <div class="technique-card advanced-card">
                    <h3 class="subsection-title text-lg font-medium text-emerald-700 mb-2">A. K-Nearest Neighbors (KNN) Imputation</h3>
                    <p class="text-base text-gray-700 leading-relaxed"><strong>How it works:</strong> For a sample with a missing value, it identifies the 'k' most similar samples (neighbors) and imputes the missing value using the average of the values from these neighbors.</p>
                    <p class="text-sm font-semibold text-gray-600 mt-2">Pros:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>More accurate than simple imputation as it uses feature relationships.</li></ul>
                    <p class="text-sm font-semibold text-gray-600 mt-2">Cons:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>Computationally expensive on large datasets.</li><li>Sensitive to the choice of 'k' and requires scaled features.</li></ul>
                    <p class="text-sm font-semibold text-gray-600 mt-2">When to use:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>When you believe the missing value is related to other features in the dataset.</li></ul>
                    <div class="code-block mt-3">
                        <pre><code><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> KNNImputer
df_knn = df.copy()
imputer_knn = KNNImputer(n_neighbors=3)
df_knn_imputed = pd.DataFrame(imputer_knn.fit_transform(df_knn), columns=df.columns)
<span class="keyword">print</span>(<span class="string">"\nDataFrame after KNN Imputation:"</span>)
<span class="keyword">print</span>(df_knn_imputed)</code></pre>
                    </div>
                    <div class="viz-card no-print mt-6">
                        <h4 class="detail-title text-lg font-medium text-indigo-700 mb-2">Interactive Demo: The Impact of `n_neighbors` (k)</h4>
                        <p class="text-sm text-gray-700 leading-relaxed mb-4">The choice of `n_neighbors` involves a trade-off: small `k` is sensitive to local noise (high variance), while large `k` might over-simplify and trend toward a global mean (high bias).</p>
                        <h5 class="text-base font-medium text-gray-700 text-center mt-6 mb-4">Select a 'k' value to see how the imputed salary changes:</h5>
                        <div class="flex justify-center items-center space-x-4 mb-4">
                            <button class="selector-btn bg-blue-500 text-white font-semibold py-2 px-4 rounded-lg shadow" data-k="1">k = 1</button>
                            <button class="selector-btn bg-blue-500 text-white font-semibold py-2 px-4 rounded-lg shadow" data-k="3">k = 3</button>
                            <button class="selector-btn bg-blue-500 text-white font-semibold py-2 px-4 rounded-lg shadow" data-k="9">k = 9</button>
                        </div>
                        <div class="chart-container">
                            <canvas id="knnChart"></canvas>
                        </div>
                        <div id="knn-explanation" class="text-center text-gray-700 mt-4 p-3 bg-gray-100 rounded-md text-sm leading-relaxed">
                            Select a 'k' value to begin the interactive demonstration.
                        </div>
                    </div>
                </div>

                <div class="technique-card advanced-card">
                    <h3 class="subsection-title text-lg font-medium text-emerald-700 mb-2">B. Iterative Imputation (MICE)</h3>
                    <p class="text-base text-gray-700 leading-relaxed"><strong>How it works:</strong> This advanced method models each feature with missing values as a function of other features. It iterates through this process, refining its guesses in each round until the imputed values converge.</p>
                     <p class="text-sm font-semibold text-gray-600 mt-2">When to use:</p>
                    <ul class="list-disc list-inside text-sm text-gray-600 ml-5"><li>When accuracy is paramount and computational time is available.</li><li>When data relationships are complex and need to be preserved.</li></ul>
                     <div class="code-block mt-3">
                        <pre><code><span class="keyword">from</span> sklearn.experimental <span class="keyword">import</span> enable_iterative_imputer
<span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> IterativeImputer
df_iterative = df.copy()
imputer_iterative = IterativeImputer(max_iter=10, random_state=0)
df_iterative_imputed = pd.DataFrame(imputer_iterative.fit_transform(df_iterative), columns=df.columns)
<span class="keyword">print</span>(<span class="string">"\nDataFrame after Iterative Imputation:"</span>)
<span class="keyword">print</span>(df_iterative_imputed)</code></pre>
                    </div>
                     <div class="viz-card no-print mt-6">
                        <h4 class="detail-title text-lg font-medium text-indigo-700 mb-2">Interactive Demo: The Impact of `max_iter`</h4>
                         <p class="text-base text-gray-700 leading-relaxed mb-4">`max_iter` controls how many imputation rounds are performed. A small value might not allow the model to <span class="interactive-term" data-definition="Convergence, in this context, means the imputed values stabilize and stop changing significantly between iterations.">converge</span>, while a very large value can be computationally expensive for diminishing returns.</p>
                         <h5 class="text-base font-medium text-gray-700 text-center mt-6 mb-4">Select a missing value to visualize its convergence over iterations:</h5>
                         <div class="flex justify-center items-center space-x-4 mb-4">
                            <button class="selector-btn bg-blue-500 text-white font-semibold py-2 px-4 rounded-lg shadow" data-feature="age">Impute Missing Age</button>
                            <button class="selector-btn bg-blue-500 text-white font-semibold py-2 px-4 rounded-lg shadow" data-feature="salary">Impute Missing Salary</button>
                        </div>
                        <div class="chart-container">
                            <canvas id="miceChart"></canvas>
                        </div>
                         <div id="mice-explanation" class="text-center text-gray-700 mt-4 p-3 bg-gray-100 rounded-md text-sm leading-relaxed">
                            Select a feature to visualize its imputation convergence.
                        </div>
                    </div>
                </div>
            </section>
            
            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 4: Visualizing the Impact of Imputation</h2>
                <div class="bg-gray-50 p-4 rounded-lg viz-card no-print">
                    <div class="chart-container">
                        <canvas id="kdeChart"></canvas>
                    </div>
                </div>
            </section>
            
            <section class="mb-8 content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Task 5: Data Transformation (Scaling & Encoding)</h2>
                 <p class="text-base text-gray-700 leading-relaxed">After imputation, scaling and encoding are the final steps to prepare data for modeling...</p>
                 <!-- Remainder of this section would include code and explanations for StandardScaler and One-Hot Encoding -->
            </section>

             <section class="content-section">
                <h2 class="section-title text-xl font-semibold text-slate-800 mb-3">Key Takeaways for Session 11</h2>
                <ul class="list-disc list-inside text-base text-gray-700 ml-5 space-y-1 leading-relaxed">
                    <li>The choice of imputation method and its hyperparameters (like `n_neighbors` or `max_iter`) involves critical trade-offs between accuracy, computational cost, and potential data distortion.</li>
                    <li>Interactive visualizations are powerful tools for understanding how hyperparameters influence model behavior and outcomes.</li>
                    <li>A complete preprocessing pipeline often involves a sequence of imputation, scaling, and encoding steps.</li>
                </ul>
            </section>
        </article>

        <footer class="text-center mt-12 py-6 border-t border-gray-300"> 
            <div class="mb-4"> 
                 <img src="../faceprep-logo-multicolor.png" alt="FACE Prep Logo" class="h-10 mx-auto footer-logo-print" onerror="this.style.display='none'; this.onerror=null;"> 
            </div>
            <p class="text-base text-gray-600">&copy; <span id="currentYearModule"></span> FACE Prep Campus (www.faceprep.in). All rights reserved.</p>
        </footer>
    </div>

    <script>
        document.getElementById('currentYearModule').textContent = new Date().getFullYear();

        const interactiveTerms = document.querySelectorAll('.interactive-term');
        const tooltip = document.querySelector('.definition-tooltip');
        if (tooltip) {
            interactiveTerms.forEach(term => {
                term.addEventListener('click', (e) => { 
                    tooltip.textContent = term.dataset.definition;
                    tooltip.style.display = 'block';
                    const termRect = term.getBoundingClientRect();
                    tooltip.style.top = `${termRect.bottom + window.scrollY + 8}px`;
                    tooltip.style.left = `${termRect.left + window.scrollX}px`;
                });
            });
            document.addEventListener('click', function(event) {
                if (!event.target.classList.contains('interactive-term')) {
                    tooltip.style.display = 'none';
                }
            });
        }
        
        const kdeCtx = document.getElementById('kdeChart');
        if (kdeCtx) {
            new Chart(kdeCtx, {
                type: 'line',
                data: { labels: [20, 25, 30, 35, 40, 45, 50, 55, 60, 65], datasets: [ { label: 'Original Data Distribution', data: [0.5, 2.5, 3.5, 4.0, 3.8, 3.0, 2.0, 1.5, 1.0, 0.5], borderColor: 'rgb(59, 130, 246)', backgroundColor: 'rgba(59, 130, 246, 0.1)', fill: true, tension: 0.4, borderWidth: 2 }, { label: 'After Mean Imputation', data: [0.4, 2.0, 2.8, 5.5, 3.0, 2.4, 1.6, 1.2, 0.8, 0.4], borderColor: 'rgb(239, 68, 68)', fill: false, tension: 0.4, borderWidth: 2, borderDash: [5, 5] }, { label: 'After Advanced Imputation (Conceptual)', data: [0.5, 2.4, 3.4, 4.1, 3.7, 3.1, 2.1, 1.6, 1.1, 0.6], borderColor: 'rgb(22, 163, 74)', fill: false, tension: 0.4, borderWidth: 2, borderDash: [5, 5] } ] },
                options: { responsive: true, maintainAspectRatio: false, plugins: { title: { display: true, text: "Effect of Imputation Methods on 'Age' Distribution (KDE Plot)", font: { size: 16 } }, legend: { position: 'top' } }, scales: { y: { title: { display: true, text: 'Density' } }, x: { title: { display: true, text: 'Age' } } } }
            });
        }

        const knnCtx = document.getElementById('knnChart');
        const knnExplanation = document.getElementById('knn-explanation');
        const kSelectorBtns = document.querySelectorAll('.selector-btn[data-k]');

        if (knnCtx && knnExplanation && kSelectorBtns.length > 0) {
            const allDataPoints = [ {x: 5, y: 70}, {x: 10, y: 90}, {x: 7, y: 65}, {x: 20, y: 120}, {x: 2, y: 45}, {x: 15, y: 95}, {x: 25, y: 140}, {x: 6, y: 72}, {x: 18, y: 110}, {x: 12, y: 88}, {x: 35, y: 150}, {x: 14, y: 85} ];
            const targetPoint = {x: 16, y: null};
            const neighbors = allDataPoints.map(p => ({ ...p, dist: Math.sqrt(Math.pow(p.x - targetPoint.x, 2)) })).sort((a, b) => a.dist - b.dist);
            const knnChart = new Chart(knnCtx, {
                type: 'scatter',
                data: { datasets: [ { label: 'Existing Data', data: allDataPoints, backgroundColor: 'rgb(107, 114, 128)' }, { label: 'Target Point (to impute)', data: [ {x: targetPoint.x, y: 105} ], backgroundColor: 'rgb(239, 68, 68)', pointRadius: 8, pointStyle: 'star'}, { label: 'Neighbors', data: [], backgroundColor: 'rgb(22, 163, 74)', pointRadius: 6 } ] },
                options: { responsive: true, maintainAspectRatio: false, plugins: { title: { display: true, text: "KNN Imputation: Effect of 'k'", font: {size: 16} }, legend: { position: 'bottom' } }, scales: { x: { title: { display: true, text: 'Experience (Years)'} }, y: { title: { display: true, text: 'Salary (in 1000s)'} } } }
            });
            const updateKnnChart = (k) => {
                const kNeighbors = neighbors.slice(0, k);
                const imputedSalary = kNeighbors.reduce((acc, p) => acc + p.y, 0) / k;
                knnChart.data.datasets[1].data = [{x: targetPoint.x, y: imputedSalary}];
                knnChart.data.datasets[2].data = kNeighbors;
                knnChart.update();
                const neighborSalaries = kNeighbors.map(p => p.y).join(', ');
                knnExplanation.innerHTML = `With <strong>k=${k}</strong>, the neighbors have salaries of [${neighborSalaries}].<br>The imputed salary is their average: <strong>${imputedSalary.toFixed(2)}k</strong>.`;
            };
            kSelectorBtns.forEach(btn => {
                btn.addEventListener('click', () => {
                    kSelectorBtns.forEach(b => b.classList.remove('active'));
                    btn.classList.add('active');
                    updateKnnChart(parseInt(btn.dataset.k));
                });
            });
            kSelectorBtns[1].click();
        }
        
        const miceCtx = document.getElementById('miceChart');
        const miceExplanation = document.getElementById('mice-explanation');
        const miceSelectorBtns = document.querySelectorAll('.selector-btn[data-feature]');
        if(miceCtx && miceExplanation && miceSelectorBtns.length > 0) {
            const iterations = Array.from({length: 15}, (_, i) => i + 1);
            const convergenceData = {
                age: [30.5, 35.2, 37.8, 38.9, 39.4, 39.6, 39.7, 39.75, 39.78, 39.8, 39.81, 39.81, 39.82, 39.82, 39.82],
                salary: [80000, 85000, 88500, 90100, 90800, 91200, 91350, 91450, 91500, 91520, 91530, 91535, 91538, 91539, 91539]
            };
            const miceChart = new Chart(miceCtx, {
                type: 'line',
                data: { labels: iterations, datasets: [{ label: 'Imputed Value', data: [], borderColor: 'rgb(234, 88, 12)', backgroundColor: 'rgba(234, 88, 12, 0.1)', fill: false, tension: 0.2, borderWidth: 2 }] },
                options: { responsive: true, maintainAspectRatio: false, plugins: { title: { display: true, text: "Iterative Imputer: Convergence of Imputed Value", font: {size: 16} }, legend: { display: false } }, scales: { x: { title: { display: true, text: 'Iteration Number'} }, y: { title: { display: true, text: 'Imputed Value'} } } }
            });
            const updateMiceChart = (feature) => {
                miceChart.data.datasets[0].data = convergenceData[feature];
                miceChart.options.scales.y.title.text = `Imputed ${feature.charAt(0).toUpperCase() + feature.slice(1)}`;
                miceChart.update();
                const finalValue = convergenceData[feature][convergenceData[feature].length - 1];
                miceExplanation.innerHTML = `Visualizing the convergence for the missing <strong>${feature}</strong>. Notice how the imputed value changes significantly in early iterations and then stabilizes or "converges" around a value of <strong>${finalValue.toFixed(2)}</strong> after several rounds. This demonstrates why a sufficient \`max_iter\` is needed.`;
            };
            miceSelectorBtns.forEach(btn => {
                btn.addEventListener('click', () => {
                    miceSelectorBtns.forEach(b => b.classList.remove('active'));
                    btn.classList.add('active');
                    updateMiceChart(btn.dataset.feature);
                });
            });
            miceSelectorBtns[0].click();
        }
    </script>
</body>
</html>
